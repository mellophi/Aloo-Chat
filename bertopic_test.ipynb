{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5e17e7-d587-4c7b-9c8a-b4b65c5e6d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ayon/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f83c6e46-1e50-4231-910d-c41efffe77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bertopic import BERTopic\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# NLTK\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "\n",
    "# Spacy\n",
    "import spacy\n",
    "\n",
    "def make_doc_list(root='teext'):\n",
    "    data_folder = os.path.join(os.getcwd(), root)\n",
    "    filepaths = []\n",
    "    docs = []\n",
    "\n",
    "    for file in os.listdir(root):\n",
    "        filepaths.append(os.path.join(data_folder, file))\n",
    "    \n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            sentence = f.read()\n",
    "            docs.append(gensim.utils.simple_preprocess(sentence, deacc=True))\n",
    "    \n",
    "    return docs\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2b850f0-90c9-4301-9e99-da393a17c560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "docs = make_doc_list()\n",
    "data_words_nostops = remove_stopwords(docs)\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "data_lemmatized = lemmatization(data_words_nostops, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "docs = []\n",
    "\n",
    "for sentence in data_lemmatized:\n",
    "    docs.append(\" \".join(word for word in sentence))\n",
    "\n",
    "print(type(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0a42971-cc84-42ad-849b-a86149676550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cooperation shah launch world liquid nano fertiliser contain nitrogen phosphorus reduce fertiliser import dependence also take country sustainable farming increase farmer income bring input cost second variant fertiliser first series launch bottle replace bag traditional ammonium phosphate manufacturing unit establish kalol gujarat paradeep variant liquid fertiliser launch fertiliser commercial sale rs bottle less current price conventional shah say liquid dap spray plant help increase quality quantity production also help conserve soil farmer use liquid liquid increase number earthworm land thus move natural farming reduce production income add contribute lot restore fertility land reduce threat health crore cause chemical fertiliser say minister exhort farmer maximise liquid crore estimate production crore bottle dap replace lakh tonne conventional import lakh tonne lakh tonne dap lakh tonne mop muriate potash lakh tonne npk fertiliser shah note application variant help reduce usage granular urea dap initially later speak government effort strengthen cooperative sector shah say government decide create lakh new viable multi dimensional primary agricultural credit society pac cover uncovered panchayat country year convergence various exist scheme department fishery dairye also say model law pac send state already adopt model law say multi dimensional pac single pac create combine pac provide multi usage service fishery provide financial loan farmer dairy rejuvenate pac also help improve income minister add\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fbf2d4d-70ea-4d55-8a74-b2606fe1be89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic  Count                              Name\n",
      "0     -1     52            -1_say_joint_also_year\n",
      "1      0    113      0_say_court_party_government\n",
      "2      1     37     1_inflation_price_growth_year\n",
      "3      2     34            2_get_battery_also_new\n",
      "4      3     25  3_record_temperature_case_degree\n",
      "5      4     22         4_say_minister_visit_shah\n",
      "6      5     21         5_marriage_say_rule_right\n",
      "7      6     16              6_run_ball_team_game\n",
      "8      7     15     7_indian_sudan_evacuation_say\n",
      "9      8     15    8_company_business_work_future\n"
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic()\n",
    "# docs = make_doc_list()\n",
    "\n",
    "topic, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "print(topic_model.get_topic_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05adb624-4e1f-4094-94b9-412f77edf3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('say', 0.04650322257491916),\n",
       " ('court', 0.03523897343823865),\n",
       " ('party', 0.02867961785451503),\n",
       " ('government', 0.025850441663979908),\n",
       " ('police', 0.02440162370560566),\n",
       " ('leader', 0.023958886605963375),\n",
       " ('case', 0.023340471672549688),\n",
       " ('state', 0.023236106258236702),\n",
       " ('people', 0.022007886877554495),\n",
       " ('judge', 0.020565828751426762)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7283e9fb-cdfa-41b2-925d-fe6f8deedfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_document_info(docs).to_csv('document_topics_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cdc1f99-3831-4b18-a471-b087e7580c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('topics.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(topic_model.get_topics(), f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
